{
  "$schema": "https://ui.shadcn.com/schema/registry-item.json",
  "name": "realtime-transcriber-01",
  "type": "registry:block",
  "description": "Scribe V2 Realtime Transcriber",
  "dependencies": [
    "streamdown"
  ],
  "registryDependencies": [
    "https://ui.elevenlabs.io/r/voice-button.json",
    "button",
    "scroll-area"
  ],
  "files": [
    {
      "path": "blocks/realtime-transcriber-01/page.tsx",
      "content": "\"use client\"\n\nimport { useCallback, useEffect, useRef, useState } from \"react\"\nimport { Copy } from \"lucide-react\"\nimport { Streamdown } from \"streamdown\"\n\nimport { cn } from \"@/lib/utils\"\nimport { Button } from \"@/components/ui/button\"\nimport { ScrollArea } from \"@/components/ui/scroll-area\"\nimport { ShimmeringText } from \"@/components/ui/shimmering-text\"\n\ninterface RecordingState {\n  isRecording: boolean\n  isProcessing: boolean\n  isConnecting: boolean\n  transcript: string\n  partialTranscript: string\n  error: string\n}\n\n// ElevenLabs WebSocket message types\ninterface InputAudioChunk {\n  message_type: \"input_audio_chunk\"\n  audio_base_64: string\n  commit: boolean\n}\n\ninterface PartialTranscriptMessage {\n  message_type: \"partial_transcript\"\n  transcript: string\n}\n\ninterface FinalTranscriptMessage {\n  message_type: \"final_transcript\"\n  transcript: string\n}\n\ninterface ErrorMessage {\n  message_type: \"error\"\n  error: string\n}\n\ntype WebSocketMessage =\n  | { message_type: \"session_started\" }\n  | PartialTranscriptMessage\n  | FinalTranscriptMessage\n  | ErrorMessage\n\n// WebSocket proxy URL - set via environment variable or use default local dev server\nconst WEBSOCKET_PROXY_URL =\n  process.env.NEXT_PUBLIC_STT_PROXY_URL || \"ws://localhost:3001\"\n\nexport default function RealtimeTranscriber01() {\n  const [recording, setRecording] = useState<RecordingState>({\n    isRecording: false,\n    isProcessing: false,\n    isConnecting: false,\n    transcript: \"\",\n    partialTranscript: \"\",\n    error: \"\",\n  })\n\n  const audioContextRef = useRef<AudioContext | null>(null)\n  const processorRef = useRef<ScriptProcessorNode | null>(null)\n  const streamRef = useRef<MediaStream | null>(null)\n  const websocketRef = useRef<WebSocket | null>(null)\n\n  // Audio refs for sound effects\n  const startSoundRef = useRef<HTMLAudioElement | null>(null)\n  const endSoundRef = useRef<HTMLAudioElement | null>(null)\n  const errorSoundRef = useRef<HTMLAudioElement | null>(null)\n  const prevRecordingRef = useRef(false)\n  const prevErrorRef = useRef(\"\")\n\n  const updateRecording = useCallback((updates: Partial<RecordingState>) => {\n    setRecording((prev) => ({ ...prev, ...updates }))\n  }, [])\n\n  const cleanupStream = useCallback(() => {\n    if (streamRef.current) {\n      streamRef.current.getTracks().forEach((track) => track.stop())\n      streamRef.current = null\n    }\n  }, [])\n\n  const cleanupWebSocket = useCallback(() => {\n    if (websocketRef.current) {\n      websocketRef.current.close()\n      websocketRef.current = null\n    }\n  }, [])\n\n  const stopRecording = useCallback(() => {\n    console.log(\"[Client] Stopping recording...\")\n\n    // Stop audio processing\n    if (processorRef.current) {\n      processorRef.current.disconnect()\n      processorRef.current = null\n    }\n\n    if (audioContextRef.current) {\n      audioContextRef.current.close()\n      audioContextRef.current = null\n    }\n\n    // Send commit to finalize transcription\n    if (websocketRef.current?.readyState === WebSocket.OPEN) {\n      const commitMessage: InputAudioChunk = {\n        message_type: \"input_audio_chunk\",\n        audio_base_64: \"\",\n        commit: true,\n      }\n      websocketRef.current.send(JSON.stringify(commitMessage))\n    }\n\n    cleanupStream()\n    updateRecording({ isRecording: false, isProcessing: true })\n  }, [cleanupStream, updateRecording])\n\n  const startRecording = useCallback(async () => {\n    try {\n      console.log(\"[Client] Starting recording...\")\n      updateRecording({\n        transcript: \"\",\n        partialTranscript: \"\",\n        error: \"\",\n        isConnecting: true,\n      })\n\n      // Get user media\n      console.log(\"[Client] Requesting microphone access...\")\n      const stream =\n        await navigator.mediaDevices.getUserMedia(AUDIO_CONSTRAINTS)\n      streamRef.current = stream\n      console.log(\"[Client] Microphone access granted\")\n\n      // Connect to WebSocket proxy\n      console.log(\"[Client] Connecting to WebSocket proxy...\")\n      const websocket = new WebSocket(WEBSOCKET_PROXY_URL)\n      websocketRef.current = websocket\n\n      websocket.onopen = () => {\n        console.log(\"[Client] WebSocket connected\")\n      }\n\n      websocket.onmessage = (event) => {\n        try {\n          const data = JSON.parse(event.data) as WebSocketMessage\n\n          switch (data.message_type) {\n            case \"session_started\":\n              console.log(\"[Client] Session started\")\n              updateRecording({ isConnecting: false, isRecording: true })\n\n              // Start AudioContext to capture raw PCM audio\n              const audioContext = new AudioContext({ sampleRate: 16000 })\n              audioContextRef.current = audioContext\n\n              const source = audioContext.createMediaStreamSource(stream)\n              const processor = audioContext.createScriptProcessor(4096, 1, 1)\n              processorRef.current = processor\n\n              let chunkCount = 0\n              processor.onaudioprocess = (event) => {\n                if (websocket.readyState === WebSocket.OPEN) {\n                  const inputBuffer = event.inputBuffer\n                  const inputData = inputBuffer.getChannelData(0)\n\n                  // Convert Float32Array to PCM16\n                  const pcmData = new Int16Array(inputData.length)\n                  for (let i = 0; i < inputData.length; i++) {\n                    pcmData[i] =\n                      Math.max(-1, Math.min(1, inputData[i])) * 0x7fff\n                  }\n\n                  // Convert to base64\n                  const uint8Array = new Uint8Array(pcmData.buffer)\n                  const base64 = btoa(String.fromCharCode(...uint8Array))\n\n                  chunkCount++\n                  if (chunkCount % 10 === 0) {\n                    console.log(`[Client] Sent ${chunkCount} PCM audio chunks`)\n                  }\n\n                  const message: InputAudioChunk = {\n                    message_type: \"input_audio_chunk\",\n                    audio_base_64: base64,\n                    commit: false,\n                  }\n\n                  websocket.send(JSON.stringify(message))\n                }\n              }\n\n              source.connect(processor)\n              processor.connect(audioContext.destination)\n\n              console.log(\n                \"[Client] AudioContext started, capturing PCM audio...\"\n              )\n              break\n\n            case \"partial_transcript\":\n              console.log(\"[Client] Partial transcript:\", data.transcript)\n              updateRecording({ partialTranscript: data.transcript })\n              break\n\n            case \"final_transcript\":\n              console.log(\"[Client] Final transcript:\", data.transcript)\n              updateRecording({\n                transcript: data.transcript,\n                partialTranscript: \"\",\n                isProcessing: false,\n              })\n              cleanupWebSocket()\n              break\n\n            case \"error\":\n              console.error(\"[Client] Error from server:\", data.error)\n              updateRecording({\n                error: data.error,\n                isProcessing: false,\n                isRecording: false,\n                isConnecting: false,\n              })\n              cleanupWebSocket()\n              break\n          }\n        } catch (err) {\n          console.error(\"[Client] Failed to parse message:\", err)\n        }\n      }\n\n      websocket.onerror = (error) => {\n        console.error(\"[Client] WebSocket error:\", error)\n        updateRecording({\n          error: \"Connection error\",\n          isRecording: false,\n          isConnecting: false,\n          isProcessing: false,\n        })\n        cleanupStream()\n        cleanupWebSocket()\n      }\n\n      websocket.onclose = (event) => {\n        console.log(\"[Client] WebSocket closed:\", event.code, event.reason)\n        if (event.code === 1008) {\n          // Policy violation - likely quota exceeded\n          updateRecording({\n            error: \"Quota exceeded. Please try again later.\",\n            isRecording: false,\n            isConnecting: false,\n            isProcessing: false,\n          })\n        }\n      }\n    } catch (err) {\n      console.error(\"[Client] Start recording error:\", err)\n      updateRecording({\n        error: err instanceof Error ? err.message : \"Failed to start recording\",\n        isRecording: false,\n        isConnecting: false,\n      })\n      cleanupStream()\n      cleanupWebSocket()\n    }\n  }, [cleanupStream, cleanupWebSocket, updateRecording])\n\n  useEffect(() => {\n    const handleKeyDown = (e: KeyboardEvent) => {\n      // Only trigger on Alt key, not when typing in input fields\n      if (\n        e.altKey &&\n        !recording.isRecording &&\n        !recording.isConnecting &&\n        !recording.isProcessing &&\n        e.target instanceof HTMLElement &&\n        ![\"INPUT\", \"TEXTAREA\"].includes(e.target.tagName)\n      ) {\n        e.preventDefault()\n        startRecording()\n      }\n    }\n\n    const handleKeyUp = (e: KeyboardEvent) => {\n      if (!e.altKey && recording.isRecording) {\n        stopRecording()\n      }\n    }\n\n    window.addEventListener(\"keydown\", handleKeyDown)\n    window.addEventListener(\"keyup\", handleKeyUp)\n    return () => {\n      window.removeEventListener(\"keydown\", handleKeyDown)\n      window.removeEventListener(\"keyup\", handleKeyUp)\n    }\n  }, [\n    recording.isRecording,\n    recording.isConnecting,\n    recording.isProcessing,\n    startRecording,\n    stopRecording,\n  ])\n\n  useEffect(() => {\n    return () => {\n      cleanupStream()\n      cleanupWebSocket()\n    }\n  }, [cleanupStream, cleanupWebSocket])\n\n  // Preload audio files on mount\n  useEffect(() => {\n    startSoundRef.current = new Audio(\n      \"https://ui.elevenlabs.io/sounds/transcriber-start.mp3\"\n    )\n    endSoundRef.current = new Audio(\n      \"https://ui.elevenlabs.io/sounds/transcriber-end.mp3\"\n    )\n    errorSoundRef.current = new Audio(\n      \"https://ui.elevenlabs.io/sounds/transcriber-error.mp3\"\n    )\n\n    // Preload by setting volume and loading\n    ;[\n      startSoundRef.current,\n      endSoundRef.current,\n      errorSoundRef.current,\n    ].forEach((audio) => {\n      audio.volume = 0.6\n      audio.load()\n    })\n  }, [])\n\n  // Play start sound when recording begins\n  useEffect(() => {\n    if (recording.isRecording && !prevRecordingRef.current) {\n      startSoundRef.current?.play().catch(() => {\n        // Ignore play errors (e.g., user hasn't interacted with page yet)\n      })\n    }\n\n    // Play end sound when recording stops\n    if (!recording.isRecording && prevRecordingRef.current) {\n      endSoundRef.current?.play().catch(() => {\n        // Ignore play errors\n      })\n    }\n\n    prevRecordingRef.current = recording.isRecording\n  }, [recording.isRecording])\n\n  // Play error sound when error occurs\n  useEffect(() => {\n    if (recording.error && recording.error !== prevErrorRef.current) {\n      errorSoundRef.current?.play().catch(() => {\n        // Ignore play errors\n      })\n    }\n    prevErrorRef.current = recording.error\n  }, [recording.error])\n\n  const displayText =\n    recording.error || recording.partialTranscript || recording.transcript\n  const hasContent = Boolean(displayText)\n\n  return (\n    <div className=\"relative mx-auto flex h-full w-full max-w-4xl flex-col items-center justify-center\">\n      {/* Bottom aura effect - Multi-layered prismatic glow */}\n      <div\n        className={cn(\n          \"pointer-events-none fixed inset-0 opacity-0 transition-opacity duration-700 ease-out\",\n          recording.isConnecting && \"opacity-40 duration-500 ease-in\",\n          recording.isRecording && \"opacity-100 duration-700 ease-in\"\n        )}\n      >\n        {/* Center bottom pool - main glow */}\n        <div\n          className=\"absolute bottom-0 left-1/2 -translate-x-1/2\"\n          style={{\n            width: \"130%\",\n            height: \"20vh\",\n            background:\n              \"radial-gradient(ellipse 100% 100% at 50% 100%, rgba(34, 211, 238, 0.5) 0%, rgba(168, 85, 247, 0.4) 35%, rgba(251, 146, 60, 0.5) 70%, transparent 100%)\",\n            filter: \"blur(80px)\",\n          }}\n        />\n\n        {/* Pulsing layer */}\n        <div\n          className=\"absolute bottom-0 left-1/2 -translate-x-1/2 animate-pulse\"\n          style={{\n            width: \"100%\",\n            height: \"18vh\",\n            background:\n              \"radial-gradient(ellipse 100% 100% at 50% 100%, rgba(134, 239, 172, 0.5) 0%, rgba(192, 132, 252, 0.4) 50%, transparent 100%)\",\n            filter: \"blur(60px)\",\n            animationDuration: \"4s\",\n          }}\n        />\n\n        {/* Left corner bloom */}\n        <div\n          className=\"absolute bottom-0 left-0\"\n          style={{\n            width: \"25vw\",\n            height: \"30vh\",\n            background:\n              \"radial-gradient(circle at 0% 100%, rgba(34, 211, 238, 0.5) 0%, rgba(134, 239, 172, 0.3) 30%, transparent 60%)\",\n            filter: \"blur(70px)\",\n          }}\n        />\n\n        {/* Left rising glow - organic curve */}\n        <div\n          className=\"absolute bottom-0 -left-8\"\n          style={{\n            width: \"20vw\",\n            height: \"45vh\",\n            background:\n              \"radial-gradient(ellipse 50% 100% at 10% 100%, rgba(34, 211, 238, 0.4) 0%, rgba(134, 239, 172, 0.25) 25%, transparent 60%)\",\n            filter: \"blur(60px)\",\n            animation: \"pulseGlow 5s ease-in-out infinite alternate\",\n          }}\n        />\n\n        {/* Right corner bloom */}\n        <div\n          className=\"absolute right-0 bottom-0\"\n          style={{\n            width: \"25vw\",\n            height: \"30vh\",\n            background:\n              \"radial-gradient(circle at 100% 100%, rgba(251, 146, 60, 0.5) 0%, rgba(251, 146, 60, 0.3) 30%, transparent 60%)\",\n            filter: \"blur(70px)\",\n          }}\n        />\n\n        {/* Right rising glow - organic curve */}\n        <div\n          className=\"absolute -right-8 bottom-0\"\n          style={{\n            width: \"20vw\",\n            height: \"45vh\",\n            background:\n              \"radial-gradient(ellipse 50% 100% at 90% 100%, rgba(251, 146, 60, 0.4) 0%, rgba(192, 132, 252, 0.25) 25%, transparent 60%)\",\n            filter: \"blur(60px)\",\n            animation: \"pulseGlow 5s ease-in-out infinite alternate-reverse\",\n          }}\n        />\n\n        {/* Shimmer overlay */}\n        <div\n          className=\"absolute bottom-0 left-1/2 -translate-x-1/2\"\n          style={{\n            width: \"100%\",\n            height: \"15vh\",\n            background:\n              \"linear-gradient(90deg, rgba(34, 211, 238, 0.3) 0%, rgba(168, 85, 247, 0.3) 30%, rgba(251, 146, 60, 0.3) 60%, rgba(134, 239, 172, 0.3) 100%)\",\n            filter: \"blur(30px)\",\n            animation: \"shimmer 8s linear infinite\",\n          }}\n        />\n      </div>\n\n      <style jsx>{`\n        @keyframes shimmer {\n          0% {\n            transform: translateX(-20%) scale(1);\n          }\n          50% {\n            transform: translateX(20%) scale(1.1);\n          }\n          100% {\n            transform: translateX(-20%) scale(1);\n          }\n        }\n        @keyframes drift {\n          0% {\n            transform: translateX(-10%) scale(1);\n          }\n          100% {\n            transform: translateX(10%) scale(1.05);\n          }\n        }\n        @keyframes pulseGlow {\n          0% {\n            opacity: 0.5;\n            transform: translateY(0) scale(1);\n          }\n          100% {\n            opacity: 0.8;\n            transform: translateY(-5%) scale(1.02);\n          }\n        }\n      `}</style>\n\n      <div className=\"relative flex h-full w-full flex-col items-center justify-center gap-8 px-8 py-12\">\n        {/* Main transcript area */}\n        <div className=\"flex min-h-[350px] w-full flex-1 items-center justify-center\">\n          {hasContent && (\n            <TranscriberTranscript\n              transcript={displayText}\n              error={recording.error}\n              isPartial={Boolean(recording.partialTranscript)}\n            />\n          )}\n\n          {!hasContent && (\n            <div className=\"flex flex-col items-center gap-8\">\n              {/* Main instruction text - transitions smoothly between states */}\n              <div className=\"relative min-h-[48px] min-w-[500px] flex items-center justify-center\">\n                <div\n                  className={cn(\n                    \"absolute inset-0 flex items-center justify-center transition-opacity duration-500\",\n                    recording.isConnecting\n                      ? \"opacity-100\"\n                      : \"opacity-0 pointer-events-none\"\n                  )}\n                >\n                  <ShimmeringText\n                    text=\"Connecting...\"\n                    className=\"text-2xl font-light tracking-wide whitespace-nowrap\"\n                  />\n                </div>\n                <div\n                  className={cn(\n                    \"absolute inset-0 flex items-center justify-center transition-opacity duration-500\",\n                    recording.isRecording\n                      ? \"opacity-100\"\n                      : \"opacity-0 pointer-events-none\"\n                  )}\n                >\n                  <ShimmeringText\n                    text=\"Start talking\"\n                    className=\"text-3xl font-light tracking-wide whitespace-nowrap\"\n                  />\n                </div>\n                <div\n                  className={cn(\n                    \"absolute inset-0 flex items-center justify-center transition-opacity duration-500\",\n                    !recording.isConnecting && !recording.isRecording\n                      ? \"opacity-100\"\n                      : \"opacity-0 pointer-events-none\"\n                  )}\n                >\n                  <div className=\"flex items-center gap-3\">\n                    <span className=\"text-muted-foreground/70 text-2xl font-light tracking-wide whitespace-nowrap\">\n                      Press and hold\n                    </span>\n                    <kbd className=\"border-border inline-flex h-8 items-center rounded-md border px-3 font-mono text-base font-medium shadow-sm select-none bg-transparent\">\n                      <ShimmeringText text=\"âŒ¥ Option\" className=\"text-base\" />\n                    </kbd>\n                  </div>\n                </div>\n              </div>\n\n              {/* Secondary text - always present but fades out */}\n              <p\n                className={cn(\n                  \"text-muted-foreground/40 text-center text-sm font-light transition-opacity duration-500\",\n                  recording.isConnecting || recording.isRecording\n                    ? \"opacity-0\"\n                    : \"opacity-100\"\n                )}\n              >\n                Release when finished\n              </p>\n            </div>\n          )}\n        </div>\n\n      </div>\n    </div>\n  )\n}\n\nconst TranscriberTranscript = ({\n  transcript,\n  error,\n  isPartial,\n}: {\n  transcript: string\n  error: string\n  isPartial?: boolean\n}) => {\n  return (\n    <div className=\"animate-in fade-in slide-in-from-bottom-8 relative w-full duration-700\">\n      <ScrollArea className=\"max-h-[450px] w-full\">\n        <div\n          className={cn(\n            \"text-foreground/90 px-12 py-8 text-center text-xl leading-relaxed font-light\",\n            error && \"text-red-500\",\n            isPartial && \"text-foreground/60\"\n          )}\n        >\n          <Streamdown>{transcript}</Streamdown>\n        </div>\n      </ScrollArea>\n      {transcript && !error && !isPartial && (\n        <Button\n          variant=\"ghost\"\n          size=\"icon\"\n          className=\"absolute top-4 right-4 h-8 w-8 opacity-0 transition-opacity hover:opacity-60\"\n          onClick={() => {\n            navigator.clipboard.writeText(transcript)\n          }}\n          aria-label=\"Copy transcript\"\n        >\n          <Copy className=\"h-4 w-4\" />\n        </Button>\n      )}\n    </div>\n  )\n}\n\nconst AUDIO_CONSTRAINTS: MediaStreamConstraints = {\n  audio: {\n    echoCancellation: true,\n    noiseSuppression: true,\n    autoGainControl: true,\n    channelCount: 1,\n  },\n}\n",
      "type": "registry:page",
      "target": "app/realtime-transcriber-01/page.tsx"
    }
  ],
  "meta": {
    "iframeHeight": "800px",
    "container": "w-full bg-surface min-h-svh flex px-4 py-12 items-center md:py-20 justify-center min-w-0",
    "mobile": "component"
  },
  "categories": [
    "audio"
  ]
}